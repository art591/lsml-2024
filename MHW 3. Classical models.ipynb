{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Мини задание 3\n",
    "\n",
    "Продолжаем работать с задачкой на Kaggle про предсказание клика на рекламу - https://www.kaggle.com/c/avito-context-ad-clicks\n",
    "\n",
    "В этот раз нужно уже полноценно решить поставленную задачу.\n",
    "\n",
    "**1. [+7 баллов]** Из всех имеющихся данных необходимо составить датасет из **минимум 10 логических признаков**. Под логическим признаком имеется в виду то, что например кодирование категориального признака или текста в виде OheHot\\BoW не считается за кучу признаков - конкретный текст считается за 1 признак, категориальный признак считается за 1 признак.\n",
    "\n",
    "Всю работу по обработке данных и сборке финального датасета необходимо провести с помощью **спарка**.\n",
    "Финальный датасет должен быть закодирован в **формате Vowpal Wabbit**.\n",
    "\n",
    "**Важно** Следите за тем, чтобы исходное количество объектов не изменилось. При неаккуратной работе с join в sql вы можете начать терять какие-то записи, что плохо. Как минимум это означает, что вы не сможете собрать такие же признаки для тестовой выборки, которую предлагают в задаче.\n",
    "\n",
    "**Важно** Обратите внимание, что в задаче стоит вопрос именно про контекстуальную рекламу, а не про всю существующую.\n",
    "\n",
    "\n",
    "\n",
    "**2. [+8 баллов]** Разделите ваш датасет на обучающую и тестовую выборку. Обучите **логистическую регрессию** с помощью **Vowpal Wabbit**. \n",
    "\n",
    "Сделайте бинарные предсказания и посчитайте Accuracy, Presicion и Recall на тестовой выборке. \n",
    "Сделайте предсказания вероятностей и посчитайте LogLoss. (Эта же метрика используется в Kaggle для оценивания вашего решения).\n",
    "\n",
    "Посчитайте ответы для тестовой выборки, которая предлагается в задании и отправьте в Kaggle (само соревнование уже давно закончилось, но вы все еще можете присылать туда свои решения и система будет вас оценивать). В решении приложите скриншот того, какой скор вам выдал Kaggle.\n",
    "\n",
    "**Важно** В сдаваемом ноубуке должны присутствовать такие элементы\n",
    "* Код на Spark, который собирает датасет\n",
    "* Команды запуска VW для его обучения\n",
    "* Подсчитанные метрики качества (и соответственно код, который их считает)\n",
    "* Скриншот из Kaggle, на котором видно вашу посылку и подсчитанную метрику качества\n",
    "\n",
    "В рамках этого дз нет трешхолдов по получившимся метрикам. Тут от вас нужно больше разобраться в полном пайплайне сбора признаков, их переводе в другую кодировку и запуске **Vowpal Wabbit** для получения результата.\n",
    "\n",
    "Если посчитаете что изначальный объем данных под обучение вы не можете переварить (он порядка 130млн строк), можете обрезать файл для трейна (который будете резать на трейн и валидацию далее) до 30-40млн строк, по идее такой объем трейн выборки тоже может быть корректным под это дз. Пожалуйста, не отрезайте в трейн совсем маленькое число данных для получения результатов работы модели, такие решения мы будем сильно резать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
